{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfd9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATS VS DOGS CLASSIFICATION WITH TRANSFER LEARNING ===\n",
      "\n",
      "1. LOADING DATASET...\n",
      "Loading cats images...\n",
      "Loading dogs images...\n",
      "\n",
      "Total images loaded: 0\n",
      "Cats: 0, Dogs: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal images loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_all)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.sum(y_all\u001b[38;5;250m \u001b[39m==\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Dogs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.sum(y_all\u001b[38;5;250m \u001b[39m==\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_all\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Dataset paths\n",
    "cats_dir = 'EXP_4_DATASET/cats_set'\n",
    "dogs_dir = 'EXP_4_DATASET/dogs_set'\n",
    "class_names = ['cats', 'dogs']\n",
    "\n",
    "print(\"=== CATS VS DOGS CLASSIFICATION WITH TRANSFER LEARNING ===\\n\")\n",
    "\n",
    "# 1. DATASET LOADING\n",
    "print(\"1. LOADING DATASET...\")\n",
    "\n",
    "def load_cats_dogs_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Loading cats images...\")\n",
    "    if os.path.exists(cats_dir):\n",
    "        cat_files = [f for f in os.listdir(cats_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        print(f\"Found {len(cat_files)} cat images\")\n",
    "        \n",
    "        for filename in cat_files:\n",
    "            img_path = os.path.join(cats_dir, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (224, 224))\n",
    "                    images.append(img)\n",
    "                    labels.append(0)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(\"Loading dogs images...\")\n",
    "    if os.path.exists(dogs_dir):\n",
    "        dog_files = [f for f in os.listdir(dogs_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        print(f\"Found {len(dog_files)} dog images\")\n",
    "        \n",
    "        for filename in dog_files:\n",
    "            img_path = os.path.join(dogs_dir, filename)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (224, 224))\n",
    "                    images.append(img)\n",
    "                    labels.append(1)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_all, y_all = load_cats_dogs_dataset()\n",
    "print(f\"\\nTotal images loaded: {len(X_all)}\")\n",
    "print(f\"Cats: {np.sum(y_all == 0)}, Dogs: {np.sum(y_all == 1)}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} images\")\n",
    "print(f\"Test set: {X_test.shape[0]} images\")\n",
    "\n",
    "# 2. EXPLORATORY DATA ANALYSIS AND PREPROCESSING\n",
    "print(\"\\n2. EXPLORATORY DATA ANALYSIS...\")\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "plt.bar([class_names[i] for i in unique], counts, color=['orange', 'blue'])\n",
    "plt.title('Training Set Class Distribution')\n",
    "plt.ylabel('Number of Images')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sample_indices = [np.where(y_train == 0)[0][0], np.where(y_train == 1)[0][0]]\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    plt.subplot(2, 3, 3 + i)\n",
    "    plt.imshow(X_train[idx])\n",
    "    plt.title(f'Sample {class_names[i].capitalize()}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    class_idx = i % 2\n",
    "    sample_idx = np.where(y_train == class_idx)[0][i//2]\n",
    "    axes[i//4, i%4].imshow(X_train[sample_idx])\n",
    "    axes[i//4, i%4].set_title(class_names[class_idx])\n",
    "    axes[i//4, i%4].axis('off')\n",
    "plt.suptitle('Random Samples from Dataset')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "y_train_categorical = to_categorical(y_train, 2)\n",
    "y_test_categorical = to_categorical(y_test, 2)\n",
    "\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train_categorical, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Final training set: {X_train_split.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "\n",
    "# 3. BUILDING TRANSFER LEARNING MODEL\n",
    "print(\"\\n3. BUILDING TRANSFER LEARNING MODEL...\")\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# 4. TRAINING THE MODEL\n",
    "print(\"\\n4. TRAINING MODEL...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "print(\"Phase 1: Feature Extraction (10 epochs)\")\n",
    "history1 = model.fit(\n",
    "    datagen.flow(X_train_split, y_train_split, batch_size=32),\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nPhase 2: Fine-tuning\")\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning (10 more epochs)\")\n",
    "history2 = model.fit(\n",
    "    datagen.flow(X_train_split, y_train_split, batch_size=32),\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_combined = {\n",
    "    'accuracy': history1.history['accuracy'] + history2.history['accuracy'],\n",
    "    'val_accuracy': history1.history['val_accuracy'] + history2.history['val_accuracy'],\n",
    "    'loss': history1.history['loss'] + history2.history['loss'],\n",
    "    'val_loss': history1.history['val_loss'] + history2.history['val_loss']\n",
    "}\n",
    "\n",
    "# 5. MODEL EVALUATION\n",
    "print(\"\\n5. MODEL EVALUATION...\")\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_classes_val = np.argmax(y_pred_val, axis=1)\n",
    "y_true_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_classes_test = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "accuracy_val = accuracy_score(y_true_val, y_pred_classes_val)\n",
    "precision_val = precision_score(y_true_val, y_pred_classes_val, average='weighted')\n",
    "recall_val = recall_score(y_true_val, y_pred_classes_val, average='weighted')\n",
    "f1_val = f1_score(y_true_val, y_pred_classes_val, average='weighted')\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_classes_test)\n",
    "precision_test = precision_score(y_test, y_pred_classes_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_classes_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_classes_test, average='weighted')\n",
    "\n",
    "print(\"VALIDATION METRICS:\")\n",
    "print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Precision: {precision_val:.4f}\")\n",
    "print(f\"Recall: {recall_val:.4f}\")\n",
    "print(f\"F1-Score: {f1_val:.4f}\")\n",
    "\n",
    "print(\"\\nTEST METRICS:\")\n",
    "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1-Score: {f1_test:.4f}\")\n",
    "\n",
    "cm_val = confusion_matrix(y_true_val, y_pred_classes_val)\n",
    "tn, fp, fn, tp = cm_val.ravel()\n",
    "specificity_val = tn / (tn + fp)\n",
    "print(f\"Specificity (Validation): {specificity_val:.4f}\")\n",
    "\n",
    "# 6. VISUALIZATIONS\n",
    "print(\"\\n6. VISUALIZATIONS...\")\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.plot(history_combined['accuracy'], 'bo-', label='Training Accuracy')\n",
    "plt.plot(history_combined['val_accuracy'], 'ro-', label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.axvline(x=9, color='g', linestyle='--', alpha=0.7, label='Fine-tuning starts')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(history_combined['loss'], 'bo-', label='Training Loss')\n",
    "plt.plot(history_combined['val_loss'], 'ro-', label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.axvline(x=9, color='g', linestyle='--', alpha=0.7, label='Fine-tuning starts')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "cm_normalized = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "y_true_bin = label_binarize(y_true_val, classes=[0, 1])\n",
    "y_pred_bin = y_pred_val\n",
    "\n",
    "# âœ… Fixed ROC plotting\n",
    "for i, class_name in enumerate(class_names):\n",
    "    if y_true_bin.shape[1] > i:  # Only plot if class exists\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f'{class_name.capitalize()} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "val_scores = [accuracy_val, precision_val, recall_val, f1_val]\n",
    "test_scores = [accuracy_test, precision_test, recall_test, f1_test]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, val_scores, width, label='Validation', color='lightblue')\n",
    "plt.bar(x + width/2, test_scores, width, label='Test', color='lightcoral')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance Comparison')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "for i, (v, t) in enumerate(zip(val_scores, test_scores)):\n",
    "    plt.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    plt.text(i + width/2, t + 0.01, f'{t:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# AUC Scores\n",
    "if y_true_bin.shape[1] == 2:\n",
    "    micro_auc = roc_auc_score(y_true_bin, y_pred_bin, average='micro')\n",
    "    macro_auc = roc_auc_score(y_true_bin, y_pred_bin, average='macro')\n",
    "    print(f\"\\nMicro-average ROC AUC: {micro_auc:.4f}\")\n",
    "    print(f\"Macro-average ROC AUC: {macro_auc:.4f}\")\n",
    "\n",
    "# 7. DETAILED CLASSIFICATION REPORT\n",
    "print(\"\\n7. DETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_true_val, y_pred_classes_val, target_names=class_names))\n",
    "\n",
    "print(\"\\nTEST SET CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred_classes_test, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
